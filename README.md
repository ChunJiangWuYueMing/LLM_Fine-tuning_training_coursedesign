# LLM_Fine-tuning_training_coursedesign
# 基于小规模LLM的多种微调方法比较与分析

## 项目简介
本项目旨在深入探讨基于小规模中文大语言模型（LLM）的多种微调方法，并对其性能进行系统性比较与分析。  
通过本研究，期望为实际应用中的模型优化提供参考，并为用户选择合适的微调策略提供理论依据。

---

## 研究背景
大型语言模型 (LLM) 微调是采用预训练模型并在较小的特定数据集上进一步训练它们以满足特定任务需求的过程。  
微调方法能够弥合通用模型与特定应用之间的差距，使语言模型的功能更符合期望。

---

## 项目过程
本研究的主要目标包括：
1. **以小规模中文LLM为基础探究**  
   探讨其性能表现并挖掘推广应用的潜力。
2. **比较多种微调方法**  
   在相同目标下分析不同微调方法（如监督微调、无监督微调、冻结层微调等）的性能差异。
3. **多维度性能评估**  
   包括任务性能、参数量、推理速度等，为用户提供决策参考。
4. **探索方法融合**  
   创新性地结合多种微调方法，尝试设计更优的混合微调方案。
5. **场景适用性分析**  
   针对不同应用场景评估各方法的适用性，提升研究的广泛性与推广价值。

---

## 项目结构
```plaintext
├── data/                # 数据集存放路径
├── models/              # 预训练模型与微调后的模型
├── scripts/             # 微调相关脚本
├── results/             # 微调实验结果与评估报告
├── docs/                # 项目文档及参考资料
├── experiments/         # 实验配置及运行记录
└── README.md            # 项目介绍文件
